{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from re import X\n",
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd\n",
    "from torch.nn.utils.rnn import pack_padded_sequence\n",
    "from torch.utils.data import DataLoader\n",
    "from CustomDataset import CustomRawDataset\n",
    "from model_dispatcher import dispatch_model\n",
    "# from model_dispatcher_cnn import dispatch_model\n",
    "import config\n",
    "from torch import nn\n",
    "import os\n",
    "from glob import glob\n",
    "from torch.optim import Adam, SGD\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from datetime import date, timedelta, datetime\n",
    "import time\n",
    "import random\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from CustomDataset import custom_collate_fn\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation,TimeDistributed,RepeatVector\n",
    "from tensorflow.keras.layers import Bidirectional, GlobalMaxPool1D\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.compat.v1.keras.layers import CuDNNLSTM\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_angle_files_1 = glob(os.path.join(\"D:\\Research_Project\\My_project_22\\input\\preprocessed\", \"*\", \"*.csv\"))\n",
    "# print(raw_angle_files_1)\n",
    "all_filenames = [i for i in raw_angle_files_1]\n",
    "df = pd.concat(map(pd.read_csv, all_filenames),ignore_index=True)\n",
    "data=df\n",
    "data.to_csv(r\"D:\\Research_Project\\My_project_22\\input\\final_preprocessed_merged\\merged.csv\",index=False)\n",
    "#df=pd.read_csv(r\"D:\\Research_Project\\My_project_22\\FEATURES_EXTRACTED\\DISTANCES\\both_hand_frontup_left_leg_frontup\\aatish_both_hand_frontup_left_leg_frontup_trial1_interpolated.csv\")\n",
    "   \n",
    "# data=df\n",
    "# print(data.shape)\n",
    "# target=data['54']\n",
    "# data=data.drop(['54'],axis=1)\n",
    "# # data.head()\n",
    "# print(data.shape)\n",
    "# AutoEncoder(data)\n",
    "# data['12']=target\n",
    "# print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12260, 167)\n",
      "(12260,)\n"
     ]
    }
   ],
   "source": [
    "data=pd.read_csv(r\"D:\\Research_Project\\My_project_22\\input\\final_preprocessed_merged\\merged.csv\")\n",
    "data.head()\n",
    "target=data['166']\n",
    "# data=data.drop(['166'],axis=1)\n",
    "# data.head()\n",
    "# print(data.shape)\n",
    "# AutoEncoder(data)\n",
    "# data['12']=target\n",
    "# print(data.shape)\n",
    "print(data.shape)\n",
    "print(target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_sequences(sequences, n_steps):\n",
    "\tX, y = list(), list()\n",
    "\tfor i in range(len(sequences)):\n",
    "\t\t# find the end of this pattern\n",
    "\t\tend_ix = i + n_steps\n",
    "\t\t# check if we are beyond the dataset\n",
    "\t\tif end_ix > len(sequences):\n",
    "\t\t\tbreak\n",
    "\t\t# gather input and output parts of the pattern\n",
    "\t\tseq_x, seq_y = sequences[i:end_ix, :166], sequences[end_ix-1, 166:]\n",
    "\t\tX.append(seq_x)\n",
    "\t\ty.append(seq_y)\n",
    "\treturn np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12258, 10)\n",
      "WARNING:tensorflow:Layer lstm_28 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_29 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_30 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_31 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_28 (LSTM)              (None, 3, 128)            151040    \n",
      "                                                                 \n",
      " lstm_29 (LSTM)              (None, 64)                49408     \n",
      "                                                                 \n",
      " repeat_vector_7 (RepeatVect  (None, 3, 64)            0         \n",
      " or)                                                             \n",
      "                                                                 \n",
      " lstm_30 (LSTM)              (None, 3, 64)             33024     \n",
      "                                                                 \n",
      " lstm_31 (LSTM)              (None, 3, 128)            98816     \n",
      "                                                                 \n",
      " time_distributed_7 (TimeDis  (None, 3, 166)           21414     \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 353,702\n",
      "Trainable params: 353,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/300\n",
      "192/192 [==============================] - 17s 71ms/step - loss: 2.9271\n",
      "Epoch 2/300\n",
      "192/192 [==============================] - 13s 70ms/step - loss: 2.1090\n",
      "Epoch 3/300\n",
      "192/192 [==============================] - 13s 70ms/step - loss: 0.9144\n",
      "Epoch 4/300\n",
      "192/192 [==============================] - 14s 71ms/step - loss: 1.0627\n",
      "Epoch 5/300\n",
      "192/192 [==============================] - 14s 71ms/step - loss: 0.4927\n",
      "Epoch 6/300\n",
      "192/192 [==============================] - 14s 72ms/step - loss: -3.1029\n",
      "Epoch 7/300\n",
      "192/192 [==============================] - 14s 75ms/step - loss: -2.9485\n",
      "Epoch 8/300\n",
      "192/192 [==============================] - 14s 73ms/step - loss: -3.5731\n",
      "Epoch 9/300\n",
      "192/192 [==============================] - 14s 71ms/step - loss: -3.7496\n",
      "Epoch 10/300\n",
      "192/192 [==============================] - 14s 71ms/step - loss: -4.1753\n",
      "Epoch 11/300\n",
      "192/192 [==============================] - 13s 70ms/step - loss: -7.4850\n",
      "Epoch 12/300\n",
      "192/192 [==============================] - 14s 71ms/step - loss: -12.8181\n",
      "Epoch 13/300\n",
      "192/192 [==============================] - 13s 70ms/step - loss: -10.2662\n",
      "Epoch 14/300\n",
      "192/192 [==============================] - 15s 80ms/step - loss: -13.2793\n",
      "Epoch 15/300\n",
      "192/192 [==============================] - 15s 75ms/step - loss: -13.2173\n",
      "Epoch 16/300\n",
      "192/192 [==============================] - 17s 90ms/step - loss: -13.2136\n",
      "Epoch 17/300\n",
      "192/192 [==============================] - 14s 73ms/step - loss: -13.3471\n",
      "Epoch 18/300\n",
      "192/192 [==============================] - 16s 84ms/step - loss: -14.0467\n",
      "Epoch 19/300\n",
      "192/192 [==============================] - 14s 71ms/step - loss: -14.4454\n",
      "Epoch 20/300\n",
      "192/192 [==============================] - 14s 75ms/step - loss: -8.0894\n",
      "Epoch 21/300\n",
      "192/192 [==============================] - 18s 93ms/step - loss: -8.5462\n",
      "Epoch 22/300\n",
      "192/192 [==============================] - 14s 72ms/step - loss: -7.6516\n",
      "Epoch 23/300\n",
      "192/192 [==============================] - 14s 72ms/step - loss: -12.4231\n",
      "Epoch 24/300\n",
      "192/192 [==============================] - 16s 82ms/step - loss: -12.4422\n",
      "Epoch 25/300\n",
      "192/192 [==============================] - 15s 79ms/step - loss: -12.5195\n",
      "Epoch 26/300\n",
      "192/192 [==============================] - 15s 78ms/step - loss: -8.2806\n",
      "Epoch 27/300\n",
      "192/192 [==============================] - 15s 80ms/step - loss: -10.2956\n",
      "Epoch 28/300\n",
      "192/192 [==============================] - 16s 83ms/step - loss: -12.4475\n",
      "Epoch 29/300\n",
      "192/192 [==============================] - 19s 101ms/step - loss: -11.8914\n",
      "Epoch 30/300\n",
      "192/192 [==============================] - 17s 88ms/step - loss: -12.5635\n",
      "Epoch 31/300\n",
      "192/192 [==============================] - 15s 77ms/step - loss: -12.1728\n",
      "Epoch 32/300\n",
      "192/192 [==============================] - 17s 86ms/step - loss: -11.8755\n",
      "Epoch 33/300\n",
      "192/192 [==============================] - 17s 86ms/step - loss: -11.9314\n",
      "Epoch 34/300\n",
      "192/192 [==============================] - 17s 88ms/step - loss: -12.4296\n",
      "Epoch 35/300\n",
      "192/192 [==============================] - 17s 87ms/step - loss: -12.2732\n",
      "Epoch 36/300\n",
      "192/192 [==============================] - 17s 88ms/step - loss: -11.8073\n",
      "Epoch 37/300\n",
      "192/192 [==============================] - 15s 79ms/step - loss: -9.2368\n",
      "Epoch 38/300\n",
      "192/192 [==============================] - 14s 72ms/step - loss: -11.6829\n",
      "Epoch 39/300\n",
      "192/192 [==============================] - 14s 72ms/step - loss: -7.6937\n",
      "Epoch 40/300\n",
      "192/192 [==============================] - 16s 81ms/step - loss: -12.1860\n",
      "Epoch 41/300\n",
      "192/192 [==============================] - 49s 255ms/step - loss: -15.5361\n",
      "Epoch 42/300\n",
      "192/192 [==============================] - 16s 84ms/step - loss: -15.6132\n",
      "Epoch 43/300\n",
      "192/192 [==============================] - 15s 80ms/step - loss: -15.1164\n",
      "Epoch 44/300\n",
      "192/192 [==============================] - 32s 169ms/step - loss: -12.0312\n",
      "Epoch 45/300\n",
      "192/192 [==============================] - 15s 78ms/step - loss: -12.9172\n",
      "Epoch 46/300\n",
      "192/192 [==============================] - 15s 79ms/step - loss: -12.9898\n",
      "Epoch 47/300\n",
      "192/192 [==============================] - 15s 76ms/step - loss: -12.2295\n",
      "Epoch 48/300\n",
      "192/192 [==============================] - 14s 76ms/step - loss: -12.8426\n",
      "Epoch 49/300\n",
      "192/192 [==============================] - 14s 71ms/step - loss: -12.9782\n",
      "Epoch 50/300\n",
      "192/192 [==============================] - 13s 70ms/step - loss: -13.1362\n",
      "Epoch 51/300\n",
      "192/192 [==============================] - 14s 70ms/step - loss: -13.5813\n",
      "Epoch 52/300\n",
      "192/192 [==============================] - 14s 73ms/step - loss: -13.9594\n",
      "Epoch 53/300\n",
      "192/192 [==============================] - 14s 74ms/step - loss: -16.3090\n",
      "Epoch 54/300\n",
      "192/192 [==============================] - 14s 72ms/step - loss: -13.6730\n",
      "Epoch 55/300\n",
      "192/192 [==============================] - 14s 75ms/step - loss: -14.7175\n",
      "Epoch 56/300\n",
      "192/192 [==============================] - 14s 72ms/step - loss: -12.7119\n",
      "Epoch 57/300\n",
      "192/192 [==============================] - 14s 74ms/step - loss: -16.0689\n",
      "Epoch 58/300\n",
      "192/192 [==============================] - 14s 75ms/step - loss: -15.5058\n",
      "Epoch 59/300\n",
      "192/192 [==============================] - 14s 74ms/step - loss: -13.3306\n",
      "Epoch 60/300\n",
      "192/192 [==============================] - 14s 74ms/step - loss: -16.0897\n",
      "Epoch 61/300\n",
      "192/192 [==============================] - 14s 72ms/step - loss: -15.9612\n",
      "Epoch 62/300\n",
      "192/192 [==============================] - 14s 73ms/step - loss: -15.7183\n",
      "Epoch 63/300\n",
      "192/192 [==============================] - 15s 76ms/step - loss: -15.3216\n",
      "Epoch 64/300\n",
      "192/192 [==============================] - 14s 74ms/step - loss: -15.4169\n",
      "Epoch 65/300\n",
      "192/192 [==============================] - 14s 72ms/step - loss: -15.9403\n",
      "Epoch 66/300\n",
      "192/192 [==============================] - 14s 73ms/step - loss: -16.4209\n",
      "Epoch 67/300\n",
      "192/192 [==============================] - 14s 75ms/step - loss: -16.4861\n",
      "Epoch 68/300\n",
      "192/192 [==============================] - 15s 76ms/step - loss: -16.4665\n",
      "Epoch 69/300\n",
      "192/192 [==============================] - 14s 74ms/step - loss: -16.4932\n",
      "Epoch 70/300\n",
      "192/192 [==============================] - 14s 75ms/step - loss: -16.4197\n",
      "Epoch 71/300\n",
      "192/192 [==============================] - 14s 72ms/step - loss: -16.5030\n",
      "Epoch 72/300\n",
      "192/192 [==============================] - 14s 72ms/step - loss: -16.4311\n",
      "Epoch 73/300\n",
      "192/192 [==============================] - 14s 72ms/step - loss: -16.2204\n",
      "Epoch 74/300\n",
      "192/192 [==============================] - 14s 71ms/step - loss: -16.4574\n",
      "Epoch 75/300\n",
      "192/192 [==============================] - 15s 78ms/step - loss: -12.8829\n",
      "Epoch 76/300\n",
      "192/192 [==============================] - 28s 148ms/step - loss: -12.8400\n",
      "Epoch 77/300\n",
      "192/192 [==============================] - 14s 71ms/step - loss: -13.5456\n",
      "Epoch 78/300\n",
      "192/192 [==============================] - 14s 75ms/step - loss: -12.2331\n",
      "Epoch 79/300\n",
      "192/192 [==============================] - 15s 76ms/step - loss: -4.5078\n",
      "Epoch 80/300\n",
      "192/192 [==============================] - 15s 76ms/step - loss: -13.4164\n",
      "Epoch 81/300\n",
      "192/192 [==============================] - 15s 76ms/step - loss: -8.8324\n",
      "Epoch 82/300\n",
      "192/192 [==============================] - 14s 75ms/step - loss: -5.1836\n",
      "Epoch 83/300\n",
      "192/192 [==============================] - 27s 142ms/step - loss: -9.6100\n",
      "Epoch 84/300\n",
      "163/192 [========================>.....] - ETA: 8s - loss: -17.6477"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [31], line 30\u001b[0m\n\u001b[0;32m     28\u001b[0m model\u001b[39m.\u001b[39mcompile(optimizer\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39madam\u001b[39m\u001b[39m'\u001b[39m, loss\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mbinary_crossentropy\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     29\u001b[0m model\u001b[39m.\u001b[39msummary()\n\u001b[1;32m---> 30\u001b[0m model\u001b[39m.\u001b[39;49mfit(x, x, epochs\u001b[39m=\u001b[39;49m\u001b[39m300\u001b[39;49m, batch_size\u001b[39m=\u001b[39;49mconfig\u001b[39m.\u001b[39;49mBATCH_SIZE, verbose\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\acer\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\acer\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py:1564\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1556\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[0;32m   1557\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   1558\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1561\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[0;32m   1562\u001b[0m ):\n\u001b[0;32m   1563\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1564\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[0;32m   1565\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[0;32m   1566\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mc:\\Users\\acer\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\acer\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\acer\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[0;32m    945\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateless_fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    949\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    950\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[0;32m    951\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[1;32mc:\\Users\\acer\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2496\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2493\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m   2494\u001b[0m   (graph_function,\n\u001b[0;32m   2495\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2496\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[0;32m   2497\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[1;32mc:\\Users\\acer\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1862\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1858\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1859\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1860\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1861\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1862\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[0;32m   1863\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[0;32m   1864\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1865\u001b[0m     args,\n\u001b[0;32m   1866\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1867\u001b[0m     executing_eagerly)\n\u001b[0;32m   1868\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\acer\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[0;32m    498\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 499\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m    500\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[0;32m    501\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[0;32m    502\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m    503\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m    504\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[0;32m    505\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    506\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    507\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[0;32m    508\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    511\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[0;32m    512\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32mc:\\Users\\acer\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "# raw_angle_files_1 = glob(os.path.join(\"D:\\Research_Project\\My_project_22\\input\\preprocessed\", \"*\", \"*.csv\"))\n",
    "# # print(raw_angle_files_1)\n",
    "# all_filenames = [i for i in raw_angle_files_1]\n",
    "# df = pd.concat(map(pd.read_csv, all_filenames),ignore_index=True)\n",
    "\n",
    "# data=df\n",
    "data=pd.get_dummies(data,columns=['166'])\n",
    "data=data.to_numpy()\n",
    "x,y=split_sequences(data,3)\n",
    "print(y.shape)\n",
    "\n",
    "# target=data['26']\n",
    "# data=data.drop(['26'],axis=1)\n",
    "x_train,x_test,y_train,y_test= train_test_split(x, y, test_size = 0.2)\n",
    "\n",
    "\n",
    "\n",
    "# Model building\n",
    "n_steps=3\n",
    "n_features=166\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, activation='relu', input_shape=(n_steps,n_features), return_sequences=True))\n",
    "model.add(LSTM(64, activation='relu', return_sequences=False))\n",
    "model.add(RepeatVector(n_steps))\n",
    "model.add(LSTM(64, activation='relu', return_sequences=True))\n",
    "model.add(LSTM(128, activation='sigmoid', return_sequences=True))\n",
    "model.add(TimeDistributed(Dense(n_features)))\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "model.summary()\n",
    "model.fit(x, x, epochs=300, batch_size=config.BATCH_SIZE, verbose=1)\n",
    "# n_steps=3\n",
    "\n",
    "# model = Sequential()\n",
    "# model.add(LSTM(50, activation='relu', input_shape=(n_steps, 12), return_sequences=True))\n",
    "# model.add(LSTM(30, activation='relu'))\n",
    "# model.add(Dense(10,activation='softmax'))\n",
    "# model.add(Embedding(config.EXTRACTED_FEATURES,128))\n",
    "# model.add(Bidirectional(CuDNNLSTM(128, return_sequences=True)))\n",
    "# model.add(GlobalMaxPool1D())\n",
    "# model.add(Dropout(0.2))\n",
    "# model.add(Dense(64, activation='relu'))\n",
    "# model.add(Dropout(0.2))\n",
    "# model.add(Dense(32, activation='relu'))\n",
    "# model.add(Dropout(0.2))\n",
    "# model.add(Dense(1, activation='sigmoid'))\n",
    "#     # model = Sequential()\n",
    "#     # model.add(Embedding(num_distinct_words, embedding_output_dims, input_length=max_sequence_length))\n",
    "#     # model.add(LSTM(10))\n",
    "#     # model.add(Dense(1, activation='sigmoid'))\n",
    "#     # model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# #     model = tf.keras.Sequential([\n",
    "# #     tf.keras.layers.Embedding(config.EXTRACTED_FEATURES, 64),\n",
    "# #     tf.keras.layers.LSTM(64),\n",
    "# #     tf.keras.layers.Dense(1, activation=\"sigmoid\")\n",
    "# # ])\n",
    "#     # x_train = pad_sequences(x_train, 300)\n",
    "#     # x_test = pad_sequences(x_test, 300)\n",
    "# model.summary()\n",
    "# log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "# tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "# model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# print(x.shape)\n",
    "# history = model.fit(x_train, y_train,batch_size=config.BATCH_SIZE,epochs=100,validation_data=(x_test,y_test),verbose=1)\n",
    "# results = model.evaluate(x_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7 (tags/v3.10.7:6cc6b13, Sep  5 2022, 14:08:36) [MSC v.1933 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "229cdfb8eedfa4964725b7eb0da8d7a63b25d97a6ab808f09bd6b506844c0629"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
