{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12256, 10)\n",
      "(12256, 5, 26)\n"
     ]
    }
   ],
   "source": [
    "from re import X\n",
    "import numpy as np\n",
    "# import torch\n",
    "import pandas as pd\n",
    "# from torch.nn.utils.rnn import pack_padded_sequence\n",
    "# from torch.utils.data import DataLoader\n",
    "# from CustomDataset import CustomRawDataset\n",
    "# from model_dispatcher import dispatch_model\n",
    "# # from model_dispatcher_cnn import dispatch_model\n",
    "import config\n",
    "# from torch import nn\n",
    "import os\n",
    "from glob import glob\n",
    "from torch.optim import Adam, SGD\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import datetime\n",
    "import time\n",
    "import random\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from CustomDataset import custom_collate_fn\n",
    "import tensorflow as tf\n",
    "# from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "# from tensorflow.keras.models import Sequential\n",
    "# from tensorflow.keras.layers import Dense, BatchNormalization, Dropout, Activation\n",
    "# from tensorflow.keras.layers import LSTM, GRU\n",
    "# from tensorflow.keras.losses import BinaryCrossentropy\n",
    "# from sklearn.metrics import mean_squared_error\n",
    "# from tensorflow.keras.optimizers import Adam, SGD, RMSprop\n",
    "# from sklearn.metrics import mean_squared_error\n",
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "# from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation,TimeDistributed\n",
    "from tensorflow.keras.layers import Bidirectional, GlobalMaxPool1D\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.compat.v1.keras.layers import CuDNNLSTM\n",
    "from tensorflow.keras import layers\n",
    "random.seed(42)\n",
    "def split_sequences(sequences, n_steps):\n",
    "\tX, y = list(), list()\n",
    "\tfor i in range(len(sequences)):\n",
    "\t\t# find the end of this pattern\n",
    "\t\tend_ix = i + n_steps\n",
    "\t\t# check if we are beyond the dataset\n",
    "\t\tif end_ix > len(sequences):\n",
    "\t\t\tbreak\n",
    "\t\t# gather input and output parts of the pattern\n",
    "\t\tseq_x, seq_y = sequences[i:end_ix, :26], sequences[end_ix-1, 26:]\n",
    "\t\tX.append(seq_x)\n",
    "\t\ty.append(seq_y)\n",
    "       \n",
    "\treturn np.array(X), np.array(y)\n",
    "\n",
    "\n",
    "    # torch.cuda.set_device(0)\n",
    "    # device = torch.device(\"cuda\")\n",
    "    # print(\"GPU Name: {}\".format(torch.cuda.get_device_name(device)))\n",
    "raw_angle_files_1 = glob(os.path.join(config.INPUT_PREPROCESSED, \"*\", \"*.csv\"))\n",
    "# print(raw_angle_files_1)\n",
    "all_filenames = [i for i in raw_angle_files_1]\n",
    "df = pd.concat(map(pd.read_csv, all_filenames),ignore_index=True)\n",
    "    # print(df.shape)\n",
    "    # df = df.sample(frac = 1)\n",
    "    # # df.iloc[1:10,:]\n",
    "data=df\n",
    "data=pd.get_dummies(data,columns=['26'])\n",
    "data=data.to_numpy()\n",
    "x,y=split_sequences(data,5)\n",
    "print(y.shape)\n",
    "print(x.shape)\n",
    "    \n",
    "    # target=data['26']\n",
    "    # data=data.drop(['26'],axis=1)\n",
    "x_train,x_test,y_train,y_test= train_test_split(x, y, test_size = 0.2)\n",
    "    # x_train=x\n",
    "    # y_train=y\n",
    "    # print(x_train)\n",
    "    # x_train=x_train.to_numpy()\n",
    "    # x_test=x_test.to_numpy()\n",
    "    # y_train=y_train.to_numpy()\n",
    "    # y_test=y_test.to_numpy()\n",
    "#     # train_dl = return_dataloader('train')\n",
    "#     # val_dl = return_dataloader('val')\n",
    "\n",
    "    # Model building\n",
    "# n_steps=5\n",
    "    \n",
    "# model = Sequential()\n",
    "# model.add(LSTM(50, activation='relu', input_shape=(n_steps, config.EXTRACTED_FEATURES), return_sequences=True))\n",
    "# model.add(LSTM(30, activation='relu'))\n",
    "# model.add(Dense(10,activation='softmax'))\n",
    "#     # model.add(Embedding(config.EXTRACTED_FEATURES,128))\n",
    "    # model.add(Bidirectional(CuDNNLSTM(128, return_sequences=True)))\n",
    "    # model.add(GlobalMaxPool1D())\n",
    "    # model.add(Dropout(0.2))\n",
    "    # model.add(Dense(64, activation='relu'))\n",
    "    # model.add(Dropout(0.2))\n",
    "    # model.add(Dense(32, activation='relu'))\n",
    "    # model.add(Dropout(0.2))\n",
    "    # model.add(Dense(1, activation='sigmoid'))\n",
    "#     # model = Sequential()\n",
    "#     # model.add(Embedding(num_distinct_words, embedding_output_dims, input_length=max_sequence_length))\n",
    "#     # model.add(LSTM(10))\n",
    "#     # model.add(Dense(1, activation='sigmoid'))\n",
    "#     # model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# #     model = tf.keras.Sequential([\n",
    "# #     tf.keras.layers.Embedding(config.EXTRACTED_FEATURES, 64),\n",
    "# #     tf.keras.layers.LSTM(64),\n",
    "# #     tf.keras.layers.Dense(1, activation=\"sigmoid\")\n",
    "# # ])\n",
    "#     # x_train = pad_sequences(x_train, 300)\n",
    "#     # x_test = pad_sequences(x_test, 300)\n",
    "# model.summary()\n",
    "# %load_ext tensorboard\n",
    "# log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "# tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "# model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# print(x.shape)\n",
    "# history = model.fit(x_train, y_train,batch_size=config.BATCH_SIZE,epochs=2,validation_data=(x_test,y_test),verbose=1,callbacks=[tensorboard_callback])\n",
    "# results = model.evaluate(x_test, y_test)\n",
    "# %tensorboard --logdir logs/fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7 (tags/v3.10.7:6cc6b13, Sep  5 2022, 14:08:36) [MSC v.1933 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "229cdfb8eedfa4964725b7eb0da8d7a63b25d97a6ab808f09bd6b506844c0629"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
